# >:]

# name = rss.ticker.fetch.multiple

my $rss_url_ref = shift;
die "expected hash reference containing RSS urls"
    if not defined $rss_url_ref
    or !length($rss_url_ref)
    or ref($rss_url_ref) ne 'HASH';
my $output_file = <rss.ticker.txt_data_path>;
( my $data_dir = <rss.data.tmp_path> . '/rssdata' ) =~ s,(/|\.\.)/,/,g;
my $join_type = <rss.ticker.join_type>;
$join_type //= 'mixed';
my $seperator = '.:.';
<rss.ticker.cache_timeout> //= 3;    # 3 hours default timeout for cached feeds

my @urls;
map { push( @urls, $rss_url_ref->{$_} ) } keys( %{$rss_url_ref} );
if ( !@urls ) {
    <[base.log]>->(
        0, "<!> WARNING: no RSS-urls set up (referenced hash is empty)"
    );
    return;
}
<[base.log]>->( 2, "checking RSS feeds for new data..." );

my %failed;
my $got_updates = 0;

foreach my $rss_index ( keys( %{$rss_url_ref} ) ) {
    my $rss_url  = $rss_url_ref->{$rss_index};
    my $response = <rss.browser>->get($rss_url);
    if ( $response->code == 200 ) {
        <[base.log]>->( 2, ": got fresh RSS content..." );
        my $feed
            = <rss.parser>
            ->parse_string( encode( 'utf-8', $response->decoded_content ) );
        if ( not defined $feed ) {
            ( my $err_str = <rss.parser>->errstr ) =~ s|\n| |g;
            $err_str =~ s| +$||;
            <[base.log]>->( 0, "[!] error on URL $rss_index [ $err_str ]" );
            next;
        }
        my @txt_data;
        eval {
            foreach my $item ( $feed->query('//item') ) {
                my $node = $item->query('title');
                my $line = $node->text_content;
                push( @txt_data, $line );
            }
        };
        if ($@) {
            <[base.log]>->(
                0, "error while parsing rss URL $rss_index content [$@]"
            );
            next;
        }
        my $url_hash = <[digest.sha1]>->($rss_url);
        if ( !-d $data_dir ) {
            mkdir($data_dir)
                or die "can't create rss data dir '$data_dir'! [$!]";
            chmod( 0700, $data_dir );
        }
        my $url_data_file .= "$data_dir/$url_hash.txt";
        open( my $txt_fh, '>' . $url_data_file )
            or die "can't write to feed data file [$!]";
        {
            no warnings 'utf8';
            print {$txt_fh} join( "\n", @txt_data ) . "\n";
        }
        close($txt_fh);
        $got_updates++;
        <[base.log]>->( 2, ": : wrote txt data to '$url_data_file'" );
        <rss.browser>->commit;

    } elsif ( $response->code == 304 ) {
        <[base.log]>->( 2, ": no new content since last request" );
    } else {
        <[base.log]>->(
            0,
            "failed to access RSS url '$rss_url' ("
                . $response->status_line . ")"
        );
        $failed{$rss_url} = 1;
    }
}
return 0 if !$got_updates and !keys(%failed);
my %txt_data;
my $feed_data_count = 0;
foreach my $index ( keys( %{$rss_url_ref} ) ) {
    my $rss_url  = $rss_url_ref->{$index};
    my $url_hash = <[digest.sha1]>->($rss_url);
    my $url_data_file .= "$data_dir/$url_hash.txt";

    if ( !-f $url_data_file ) {
        <[base.log]>->(
            0, "no cached version of feed #$index present.. skipping.."
        );
        next;
    }

    if ( $failed{$rss_url} ) {
        my ($dev,  $ino,   $mode,  $nlink, $uid,     $gid, $rdev,
            $size, $atime, $mtime, $ctime, $blksize, $blocks
        ) = stat($url_data_file);
        my $file_age = sprintf( "%.2f", ( time() - $ctime ) / 3600 );

        if ( $file_age >= <rss.ticker.cache_timeout> ) {
            <[base.log]>->(
                0,
                "cached version of feed #$index has timed out ($file_age hours)"
            );
            unlink($url_data_file);
            next;
        } else {
            <[base.log]>->(
                1, "using cached version of feed #$index ($file_age hours old)"
            );
        }
    }

    open( my $r_fh, '<' . $url_data_file )
        or die "can't open feed data file '$url_data_file'! [$!]";
    @{ $txt_data{$index} } = <$r_fh>;
    close($r_fh);
    $feed_data_count++;
}

<[base.log]>->( 0, "<!> WARNING: no feed data available, ticker file empty!" )
    if !$feed_data_count;

open( my $txt_fh, '>' . $output_file . '.NEW' )
    or die "can't write to ticker data file '$output_file.NEW' [$!]";
my @output_data;
if ( $join_type eq 'mixed' ) {
    while ( keys(%txt_data) ) {
        foreach my $txt_index ( sort keys(%txt_data) ) {
            push( @output_data, shift( @{ $txt_data{$txt_index} } ) );
            delete $txt_data{$txt_index} if !@{ $txt_data{$txt_index} };
        }
    }
    print {$txt_fh} join( " $seperator ", @output_data );
} elsif ( $join_type eq 'seperate' ) {
    foreach my $txt_index ( sort keys(%txt_data) ) {
        push( @output_data,
            join( " $seperator ", @{ $txt_data{$txt_index} } ) );
        push( @output_data, "^\n" );
    }
    pop(@output_data);
    print {$txt_fh} @output_data;
} else {
    <[base.log]>->(
        0, "unknown join type '$join_type' [expected 'mixed' or 'seperate']"
    );
    close($txt_fh);
    unlink($output_file);
    return -1;
}
close($txt_fh);
move( $output_file . '.NEW', $output_file )
    or die "can't move '$output_file.NEW' to '$output_file' [$!]";
<[base.log]>->( 2, ": : wrote txt data to '$output_file'" );
return 1;
